{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j143/in-car-voice-assistant/blob/colab/notebooks/edge_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git stash save\n",
        "!git pull https://github.com/j143/in-car-voice-assistant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik9PYzfZAwxH",
        "outputId": "00336b55-4a48-468f-8b3a-d1a228a62b12"
      },
      "id": "Ik9PYzfZAwxH",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved working directory and index state WIP on main: 653ad70 diable failing actions step\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10 (delta 7), reused 10 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (10/10), 1.82 KiB | 372.00 KiB/s, done.\n",
            "From https://github.com/j143/in-car-voice-assistant\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating 653ad70..4257aa7\n",
            "Fast-forward\n",
            " requirements-awq.txt   |  3 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " scripts/awq_export.py  | 27 \u001b[32m++++++++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " scripts/export_awq.py  | 53 \u001b[32m+++++++++++++++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " scripts/train_qlora.py |  1 \u001b[31m-\u001b[m\n",
            " 4 files changed, 53 insertions(+), 31 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd in-car-voice-assistant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRXGHR_HBAfe",
        "outputId": "3d326b18-0d0c-4339-dc73-65b5645e4fd1"
      },
      "id": "sRXGHR_HBAfe",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/in-car-voice-assistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNdLo54bBKmH",
        "outputId": "6d0b440f-5cea-435d-da11-ae3d3d26794a"
      },
      "id": "DNdLo54bBKmH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/       \u001b[01;34mnotebooks\u001b[0m/                 requirements-train.txt\n",
            "\u001b[01;34mconfig\u001b[0m/            \u001b[01;34mpipeline\u001b[0m/                  requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/              QUICKSTART_EXPERIMENTS.md  role.md\n",
            "DEPLOYMENT.md      README.md                  \u001b[01;34mscripts\u001b[0m/\n",
            "Dockerfile.edge    requirements-awq.txt       STRATEGIC_ALIGNMENT.md\n",
            "Dockerfile.orin    requirements-min.txt       \u001b[01;34mtests\u001b[0m/\n",
            "IMPLEMENTATION.md  requirements-nlu.txt\n",
            "\u001b[01;34mmodels\u001b[0m/            requirements-rag.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b00389cc",
      "metadata": {
        "id": "b00389cc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc4d74a0",
      "metadata": {
        "id": "bc4d74a0"
      },
      "source": [
        "## 1. Baseline Evaluation\n",
        "\n",
        "Rule-based classifier on automotive test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5631b96c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5631b96c",
        "outputId": "fba6b30c-490f-4a0b-fb5d-551a69b4d3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Subprocess Standard Output ---\n",
            "{\n",
            "  \"total_samples\": 15,\n",
            "  \"command_accuracy\": 0.2,\n",
            "  \"technical_term_recognition_rate\": 0.1667,\n",
            "  \"error_code_recognition_rate\": 0.0,\n",
            "  \"avg_latency_ms\": 57.88,\n",
            "  \"p95_latency_ms\": 184.68,\n",
            "  \"latency_target_met\": true,\n",
            "  \"accuracy_target_met\": false\n",
            "}\n",
            "\n",
            "=== Performance Summary ===\n",
            "Command Accuracy: 20.0% (Target: ≥90%)\n",
            "Avg Latency: 57.88ms (Target: <100ms)\n",
            "Technical Term Recognition: 16.7%\n",
            "Error Code Recognition: 0.0%\n",
            "\n",
            "✓ Accuracy Target Met: False\n",
            "✓ Latency Target Met: True\n",
            "\n",
            "--- End Subprocess Standard Output ---\n",
            "--- Subprocess Standard Error ---\n",
            "2025-12-16 06:56:28.699370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765868188.720265    1206 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765868188.726131    1206 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765868188.740742    1206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765868188.740764    1206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765868188.740767    1206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765868188.740769    1206 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 06:56:28.745072: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Device set to use cpu\n",
            "\n",
            "--- End Subprocess Standard Error ---\n",
            "{\n",
            "  \"total_samples\": 15,\n",
            "  \"command_accuracy\": 0.2,\n",
            "  \"technical_term_recognition_rate\": 0.1667,\n",
            "  \"error_code_recognition_rate\": 0.0,\n",
            "  \"avg_latency_ms\": 57.88,\n",
            "  \"p95_latency_ms\": 184.68,\n",
            "  \"latency_target_met\": true,\n",
            "  \"accuracy_target_met\": false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# Run baseline evaluation\n",
        "result = subprocess.run(\n",
        "    [sys.executable, \"scripts/evaluate_domain.py\", \"--test\", \"data/automotive_domain_test.jsonl\"],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    env={\"PYTHONPATH\": \".\"},\n",
        ")\n",
        "\n",
        "print(\"--- Subprocess Standard Output ---\")\n",
        "print(result.stdout)\n",
        "print(\"--- End Subprocess Standard Output ---\")\n",
        "print(\"--- Subprocess Standard Error ---\")\n",
        "print(result.stderr)\n",
        "print(\"--- End Subprocess Standard Error ---\")\n",
        "\n",
        "# Attempt to parse the JSON output.\n",
        "try:\n",
        "    # Find the start and end of the JSON object in the stdout\n",
        "    json_start_index = result.stdout.find('{')\n",
        "    json_end_index = result.stdout.rfind('}')\n",
        "\n",
        "    if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:\n",
        "        json_string = result.stdout[json_start_index : json_end_index + 1]\n",
        "        baseline = json.loads(json_string)\n",
        "        print(json.dumps(baseline, indent=2))\n",
        "    else:\n",
        "        print(\"Warning: Could not find a complete JSON object in the subprocess output.\")\n",
        "        print(\"Please inspect the full output above.\")\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"JSONDecodeError when parsing: {e}\")\n",
        "    print(\"Could not parse the extracted JSON string. Please inspect the full output above.\")\n",
        "except IndexError:\n",
        "    print(\"Error: Subprocess stdout was empty or did not contain a newline before JSON parsing attempt.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db944c5d",
      "metadata": {
        "id": "db944c5d"
      },
      "source": [
        "## 2. QLoRA Fine-Tuning\n",
        "\n",
        "Train LoRA adapters on automotive domain data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kp8MHl8DV_s",
        "outputId": "699fefa3-01f8-434d-f75e-ca0dabebac7d"
      },
      "id": "9Kp8MHl8DV_s",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 2)) (0.49.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 3)) (0.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 4)) (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements-train.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes->-r requirements-train.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes->-r requirements-train.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements-train.txt (line 3)) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-train.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-train.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-train.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-train.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-train.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements-train.txt (line 6)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements-train.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements-train.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements-train.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements-train.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements-train.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft->-r requirements-train.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements-train.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements-train.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements-train.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements-train.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements-train.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements-train.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements-train.txt (line 4)) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9WRhsTKAGJuk"
      },
      "id": "9WRhsTKAGJuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "27e3d5fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27e3d5fa",
        "outputId": "eed50980-2f9d-4ac2-d17c-1ed4ced8fb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-16 07:20:57.005088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765869657.045556    7506 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765869657.055856    7506 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765869657.088925    7506 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765869657.088966    7506 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765869657.088975    7506 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765869657.088982    7506 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loaded 25 training samples\n",
            "Loading model: microsoft/phi-2\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:18<00:00,  9.03s/it]\n",
            "trainable params: 7,864,320 || all params: 2,787,548,160 || trainable%: 0.2821\n",
            "Starting training...\n",
            "  0% 0/6 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            " 33% 2/6 [01:28<02:48, 42.12s/it]/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            " 67% 4/6 [03:02<01:27, 43.82s/it]/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "{'loss': 10.5652, 'grad_norm': 7.510814189910889, 'learning_rate': 8e-05, 'epoch': 2.57}\n",
            "{'train_runtime': 279.3695, 'train_samples_per_second': 0.268, 'train_steps_per_second': 0.021, 'train_loss': 10.466888268788656, 'epoch': 3.0}\n",
            "100% 6/6 [04:39<00:00, 46.56s/it]\n",
            "Saved adapter to checkpoints/automotive-adapter\n"
          ]
        }
      ],
      "source": [
        "# Train QLoRA (requires GPU + requirements-train.txt)\n",
        "!python scripts/train_qlora.py --model microsoft/phi-2 --epochs 3 --output checkpoints/automotive-adapter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69470a7e"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base = \"microsoft/phi-2\"\n",
        "adapter = \"checkpoints/automotive-adapter\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(base, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base,\n",
        "    trust_remote_code=True,\n",
        "    # device_map=\"cpu\" removed as it's not supported for 4-bit/8-bit models\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, adapter)\n",
        "model.eval() # Set model to evaluation mode\n",
        "\n",
        "print(\"Loaded with adapters:\", model.peft_config.keys())\n",
        "print(\"Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "id": "69470a7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d30f5eb"
      },
      "source": [
        "# Example of testing the fine-tuned model with a sample query\n",
        "\n",
        "# Prepare an input query based on the training data format\n",
        "query = \"User: My check engine light is on. What should I do?\"\n",
        "input_ids = tok(query, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# Generate a response from the fine-tuned model\n",
        "with torch.no_grad():\n",
        "    output_tokens = model.generate(input_ids, max_new_tokens=50)\n",
        "\n",
        "# Decode the output and print it\n",
        "decoded_output = tok.decode(output_tokens[0], skip_special_tokens=True)\n",
        "print(\"--- Fine-tuned Model Response ---\")\n",
        "print(decoded_output)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(\"\\nThis output demonstrates a basic inference step with your fine-tuned model.\")\n",
        "print(\"To perform a more formal evaluation and compare it against the baseline,\")\n",
        "print(\"we would integrate this into an evaluation script (like the one used for the baseline). \")"
      ],
      "id": "8d30f5eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INXG7zDUPwY8"
      },
      "id": "INXG7zDUPwY8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ebce8b68",
      "metadata": {
        "id": "ebce8b68"
      },
      "source": [
        "## 3. AWQ Export\n",
        "\n",
        "Export quantized model for edge deployment."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLX4BeiAQCWS"
      },
      "id": "TLX4BeiAQCWS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "21aed1ad",
      "metadata": {
        "id": "21aed1ad"
      },
      "source": [
        "## 4. Comparison Table\n",
        "\n",
        "| Configuration | Accuracy | Latency (ms) | Memory (GB) | Target Met |\n",
        "|--------------|----------|--------------|-------------|------------|\n",
        "| Baseline (rule) | 93.3% | 0.01 | <0.1 | ✓ Latency |\n",
        "| + QLoRA | TBD | TBD | ~2.5 | TBD |\n",
        "| + AWQ 4-bit | TBD | TBD | <2.0 | TBD |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d76a2f4e",
      "metadata": {
        "id": "d76a2f4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd in-car-voice-assistant/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypJQc42bF06N",
        "outputId": "e8e1d404-84a0-4b7d-bbe4-1814f12c14b6"
      },
      "id": "ypJQc42bF06N",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/in-car-voice-assistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate_intent.py data/automotive_domain_test.jsonl --classifier rule --rag off"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGypTId2PgCn",
        "outputId": "bc2311b1-da1c-4d39-92a5-30aa346d7551"
      },
      "id": "zGypTId2PgCn",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/in-car-voice-assistant/scripts/evaluate_intent.py\", line 19, in <module>\n",
            "    from pipeline.end_to_end import VoiceAssistantPipeline\n",
            "ModuleNotFoundError: No module named 'pipeline'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base = \"microsoft/phi-2\"\n",
        "adapter = \"checkpoints/automotive-adapter\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(base, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base,\n",
        "    trust_remote_code=True,\n",
        "    # device_map=\"cpu\" removed as it's not supported for 4-bit/8-bit models\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, adapter)\n",
        "model.eval() # Set model to evaluation mode\n",
        "\n",
        "print(\"Loaded with adapters:\", model.peft_config.keys())\n",
        "print(\"Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "96c30ee153054165806354bcc75b12f8",
            "f79e566210a843bcbd53b65e8a4e5333",
            "7ddadcb88fb942a186e9002974c79116",
            "d30d7bc908b449a4a85370d7cdfcbde7",
            "eeb3c2cfdcee44a8a0c55cafdcef5b11",
            "8a4361ed9d6446f4a47def769dad9dc4",
            "7aff40313a38417197f556fb01f3fcfd",
            "3a2be8d764be478fa70a9679118dbedd",
            "050b77c6ee8d4539a0e1ac82ce3d9a0a",
            "2bedb6e3102c4e93a5ac2ae88d89d893",
            "b503a1e6e0ff4db296243dfec48e93be"
          ]
        },
        "collapsed": true,
        "id": "10Fk8dSgQCDf",
        "outputId": "53bf61f9-6633-4348-c997-db544225243d"
      },
      "id": "10Fk8dSgQCDf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96c30ee153054165806354bcc75b12f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mZtZ8BeBRU8_",
        "outputId": "1a0e7842-abb1-4af7-c7af-8f5d97d9a32e"
      },
      "id": "mZtZ8BeBRU8_",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.9.1\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (2025.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.1)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (1.13.1.3)\n",
            "Collecting triton==3.5.1 (from torch==2.9.1)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.1) (3.0.3)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m749.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmcompressor 0.8.1 requires torch<=2.8.0,>=2.7.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.27.5 torch-2.9.1 triton-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "functorch",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "6139437e7b8e4726ae3410cc1d129e71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTkTMmenQL1t"
      },
      "id": "LTkTMmenQL1t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Archive"
      ],
      "metadata": {
        "id": "_iE65ZtxP4Gy"
      },
      "id": "_iE65ZtxP4Gy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "40e84cdb",
        "outputId": "781cdf08-3a2e-4b35-9259-dffe9156b029"
      },
      "source": [
        "# Recompile bitsandbytes from source\n",
        "!git clone https://github.com/TimDettmers/bitsandbytes.git\n",
        "%cd bitsandbytes\n",
        "!CUDA_VERSION=126 python setup.py install\n",
        "%cd ../\n"
      ],
      "id": "40e84cdb",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bitsandbytes'...\n",
            "remote: Enumerating objects: 11598, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 11598 (delta 98), reused 64 (delta 57), pack-reused 11443 (from 3)\u001b[K\n",
            "Receiving objects: 100% (11598/11598), 3.78 MiB | 9.84 MiB/s, done.\n",
            "Resolving deltas: 100% (7885/7885), done.\n",
            "/content/in-car-voice-assistant/bitsandbytes\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'cmake_source_dir'\n",
            "  warnings.warn(msg)\n",
            "configuration error: `project.license` must be valid exactly by one definition (2 matches found):\n",
            "\n",
            "    - keys:\n",
            "        'file': {type: string}\n",
            "      required: ['file']\n",
            "    - keys:\n",
            "        'text': {type: string}\n",
            "      required: ['text']\n",
            "\n",
            "DESCRIPTION:\n",
            "    `Project license <https://peps.python.org/pep-0621/#license>`_.\n",
            "\n",
            "GIVEN VALUE:\n",
            "    \"MIT\"\n",
            "\n",
            "OFFENDING RULE: 'oneOf'\n",
            "\n",
            "DEFINITION:\n",
            "    {\n",
            "        \"oneOf\": [\n",
            "            {\n",
            "                \"properties\": {\n",
            "                    \"file\": {\n",
            "                        \"type\": \"string\",\n",
            "                        \"$$description\": [\n",
            "                            \"Relative path to the file (UTF-8) which contains the license for the\",\n",
            "                            \"project.\"\n",
            "                        ]\n",
            "                    }\n",
            "                },\n",
            "                \"required\": [\n",
            "                    \"file\"\n",
            "                ]\n",
            "            },\n",
            "            {\n",
            "                \"properties\": {\n",
            "                    \"text\": {\n",
            "                        \"type\": \"string\",\n",
            "                        \"$$description\": [\n",
            "                            \"The license of the project whose meaning is that of the\",\n",
            "                            \"`License field from the core metadata\",\n",
            "                            \"<https://packaging.python.org/specifications/core-metadata/#license>`_.\"\n",
            "                        ]\n",
            "                    }\n",
            "                },\n",
            "                \"required\": [\n",
            "                    \"text\"\n",
            "                ]\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/in-car-voice-assistant/bitsandbytes/setup.py\", line 49, in <module>\n",
            "    setup(**setup_kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 117, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 157, in setup\n",
            "    dist.parse_config_files()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/dist.py\", line 647, in parse_config_files\n",
            "    pyprojecttoml.apply_configuration(self, filename, ignore_option_errors)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/config/pyprojecttoml.py\", line 71, in apply_configuration\n",
            "    config = read_configuration(filepath, True, ignore_option_errors, dist)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/config/pyprojecttoml.py\", line 139, in read_configuration\n",
            "    validate(subset, filepath)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/config/pyprojecttoml.py\", line 60, in validate\n",
            "    raise ValueError(f\"{error}\\n{summary}\") from None\n",
            "ValueError: invalid pyproject.toml config: `project.license`.\n",
            "configuration error: `project.license` must be valid exactly by one definition (2 matches found):\n",
            "\n",
            "    - keys:\n",
            "        'file': {type: string}\n",
            "      required: ['file']\n",
            "    - keys:\n",
            "        'text': {type: string}\n",
            "      required: ['text']\n",
            "\n",
            "/content/in-car-voice-assistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ddf0c38",
        "outputId": "e4938f2d-f2c5-4880-d00c-42a8b1195da2"
      },
      "source": [
        "# Ensure peft is explicitly set to the compatible version in requirements-train.txt\n",
        "!sed -i 's/^peft$/peft==0.7.1/g' requirements-train.txt\n",
        "!cat requirements-train.txt"
      ],
      "id": "5ddf0c38",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Optional training/fine-tuning requirements\n",
            "bitsandbytes\n",
            "peft==0.7.1\n",
            "transformers==4.38.0\n",
            "torch\n",
            "scikit-learn\n",
            "pandas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "6ebf03cf",
        "outputId": "43b13f7d-a887-4d11-b7c5-a53494158b84"
      },
      "source": [
        "# Reinstall all requirements, ensuring peft is downgraded to the compatible version\n",
        "!pip install -r requirements-train.txt --force-reinstall --upgrade"
      ],
      "id": "6ebf03cf",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.49.1.dev0-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting bitsandbytes (from -r requirements-train.txt (line 2))\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting peft==0.7.1 (from -r requirements-train.txt (line 3))\n",
            "  Using cached peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting transformers==4.38.0 (from -r requirements-train.txt (line 4))\n",
            "  Using cached transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
            "Collecting torch (from -r requirements-train.txt (line 5))\n",
            "  Using cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting scikit-learn (from -r requirements-train.txt (line 6))\n",
            "  Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Collecting pandas (from -r requirements-train.txt (line 7))\n",
            "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting numpy>=1.17 (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting pyyaml (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tqdm (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.21.0 (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting safetensors (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting huggingface-hub>=0.17.0 (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub>=0.17.0 (from peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch->-r requirements-train.txt (line 5))\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch->-r requirements-train.txt (line 5))\n",
            "  Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting scipy>=1.10.0 (from scikit-learn->-r requirements-train.txt (line 6))\n",
            "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.3.0 (from scikit-learn->-r requirements-train.txt (line 6))\n",
            "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn->-r requirements-train.txt (line 6))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->-r requirements-train.txt (line 7))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->-r requirements-train.txt (line 7))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->-r requirements-train.txt (line 7))\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.17.0->peft==0.7.1->-r requirements-train.txt (line 3))\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->-r requirements-train.txt (line 7))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->-r requirements-train.txt (line 5))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r requirements-train.txt (line 5))\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.38.0->-r requirements-train.txt (line 4))\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "Using cached transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
            "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m661.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, sympy, six, setuptools, safetensors, regex, pyyaml, psutil, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, scipy, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, scikit-learn, pandas, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, bitsandbytes, accelerate, peft\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.1\n",
            "    Uninstalling triton-3.5.1:\n",
            "      Successfully uninstalled triton-3.5.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.3.20\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.3.20:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.3.20\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.13.1.3\n",
            "    Uninstalling nvidia-cufile-cu12-1.13.1.3:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.8.0\n",
            "    Uninstalling scikit-learn-1.8.0:\n",
            "      Successfully uninstalled scikit-learn-1.8.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.3\n",
            "    Uninstalling pandas-2.3.3:\n",
            "      Successfully uninstalled pandas-2.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.1\n",
            "    Uninstalling torch-2.9.1:\n",
            "      Successfully uninstalled torch-2.9.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.0\n",
            "    Uninstalling transformers-4.38.0:\n",
            "      Successfully uninstalled transformers-4.38.0\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.41.3\n",
            "    Uninstalling bitsandbytes-0.41.3:\n",
            "      Successfully uninstalled bitsandbytes-0.41.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.0\n",
            "    Uninstalling peft-0.18.0:\n",
            "      Successfully uninstalled peft-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.0 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 accelerate-1.12.0 bitsandbytes-0.49.0 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.1 fsspec-2025.12.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.3 mpmath-1.3.0 networkx-3.6.1 numpy-2.3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pandas-2.3.3 peft-0.7.1 psutil-7.1.3 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 setuptools-80.9.0 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.15.2 torch-2.9.1 tqdm-4.67.1 transformers-4.38.0 triton-3.5.1 typing-extensions-4.15.0 tzdata-2025.3 urllib3-2.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "dateutil",
                  "idna",
                  "numpy",
                  "packaging",
                  "pandas",
                  "psutil",
                  "pytz",
                  "requests",
                  "six",
                  "tqdm",
                  "urllib3"
                ]
              },
              "id": "c5b5c35da3c74717989b7569aa3e1cd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of testing the fine-tuned model with a sample query\n",
        "\n",
        "# Prepare an input query based on the training data format\n",
        "query = \"User: My check engine light is on. What should I do?\"\n",
        "input_ids = tok(query, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "# Generate a response from the fine-tuned model\n",
        "with torch.no_grad():\n",
        "    output_tokens = model.generate(input_ids, max_new_tokens=50)\n",
        "\n",
        "# Decode the output and print it\n",
        "decoded_output = tok.decode(output_tokens[0], skip_special_tokens=True)\n",
        "print(\"--- Fine-tuned Model Response ---\")\n",
        "print(decoded_output)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(\"\\nThis output demonstrates a basic inference step with your fine-tuned model.\")\n",
        "print(\"To perform a more formal evaluation and compare it against the baseline,\")\n",
        "print(\"we would integrate this into an evaluation script (like the one used for the baseline).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuEMhf6PhGz",
        "outputId": "0f465f61-842c-48e3-80a9-3bda80934814"
      },
      "id": "JWuEMhf6PhGz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'in-car-voice-assistant/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcd99d9-37ff-4122-c873-a4753f5f623c",
        "collapsed": true,
        "id": "SA9A032cPi3u"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-16 04:36:43.631197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765859803.652950   31160 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765859803.659935   31160 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765859803.677158   31160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765859803.677182   31160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765859803.677186   31160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765859803.677191   31160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loaded 25 training samples\n",
            "Loading model: microsoft/phi-2\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.53s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/in-car-voice-assistant/scripts/train_qlora.py\", line 152, in <module>\n",
            "    main()\n",
            "  File \"/content/in-car-voice-assistant/scripts/train_qlora.py\", line 141, in main\n",
            "    train_qlora(\n",
            "  File \"/content/in-car-voice-assistant/scripts/train_qlora.py\", line 75, in train_qlora\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 561, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 3558, in from_pretrained\n",
            "    dispatch_model(model, **device_map_kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/big_modeling.py\", line 502, in dispatch_model\n",
            "    model.to(device)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 2534, in to\n",
            "    raise ValueError(\n",
            "ValueError: `.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`.\n"
          ]
        }
      ],
      "source": [
        "# Train QLoRA (requires GPU + requirements-train.txt)\n",
        "!python scripts/train_qlora.py --model microsoft/phi-2 --epochs 3 --output checkpoints/automotive-adapter"
      ],
      "id": "SA9A032cPi3u"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-awq.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ehC6XZ7ODiwS",
        "outputId": "f3601be9-c529-438a-8998-6136c78639f9"
      },
      "id": "ehC6XZ7ODiwS",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements-awq.txt (line 4)) (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements-awq.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements-awq.txt (line 6)) (1.12.0)\n",
            "Collecting llmcompressor[transformers] (from -r requirements-awq.txt (line 3))\n",
            "  Downloading llmcompressor-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "\u001b[33mWARNING: llmcompressor 0.8.1 does not provide the extra 'transformers'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting loguru<=0.7.3,>=0.7.2 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml<=6.0.3,>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: numpy<=2.3.3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: requests<=2.32.5,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: tqdm<=4.67.1,>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (4.67.1)\n",
            "Collecting torch (from -r requirements-awq.txt (line 5))\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting transformers (from -r requirements-awq.txt (line 4))\n",
            "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<=4.1.1,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (4.0.0)\n",
            "Collecting accelerate (from -r requirements-awq.txt (line 6))\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nvidia-ml-py<=13.580.82,>=12.560.30 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading nvidia_ml_py-13.580.82-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pillow<=11.3.0,>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (11.3.0)\n",
            "Collecting compressed-tensors==0.12.2 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements-awq.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements-awq.txt (line 5)) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch->-r requirements-awq.txt (line 5))\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements-awq.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements-awq.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements-awq.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements-awq.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3)) (1.17.0)\n",
            "Downloading compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m826.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m798.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-13.580.82-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llmcompressor-0.8.1-py3-none-any.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.2/273.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-ml-py, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, transformers, torch, compressed-tensors, accelerate, llmcompressor\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 13.590.44\n",
            "    Uninstalling nvidia-ml-py-13.590.44:\n",
            "      Successfully uninstalled nvidia-ml-py-13.590.44\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.10.1 compressed-tensors-0.12.2 llmcompressor-0.8.1 loguru-0.7.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-ml-py-13.580.82 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 transformers-4.56.2 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia",
                  "pynvml",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "c828558de9e14911912380ed8731a6eb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9UV4EpUHLE9I"
      },
      "id": "9UV4EpUHLE9I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinstall remaining requirements-awq.txt dependencies (transformers, accelerate), which should keep torch==2.9.1\n",
        "!pip install --force-reinstall -r requirements-awq.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5aee234e-3f5e-40cf-ebbc-6dcf3f13a103",
        "id": "xkGgEoRfLFN_"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate (from -r requirements-awq.txt (line 4))\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting llmcompressor[transformers] (from -r requirements-awq.txt (line 3))\n",
            "  Using cached llmcompressor-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "\u001b[33mWARNING: llmcompressor 0.8.1 does not provide the extra 'transformers'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting loguru<=0.7.3,>=0.7.2 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pyyaml<=6.0.3,>=6.0.1 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting numpy<=2.3.3,>=2.0.0 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<=2.32.5,>=2.32.2 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm<=4.67.1,>=4.66.3 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<=2.8.0,>=2.7.0 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting transformers<=4.56.2,>=4.53.0 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting datasets<=4.1.1,>=4.0.0 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting accelerate (from -r requirements-awq.txt (line 4))\n",
            "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nvidia-ml-py<=13.580.82,>=12.560.30 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_ml_py-13.580.82-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting pillow<=11.3.0,>=10.4.0 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting compressed-tensors==0.12.2 (from llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pydantic>=2.0 (from compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting huggingface_hub>=0.21.0 (from accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting filelock (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting shellingham (from huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting typer-slim (from huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<=2.32.5,>=2.32.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting setuptools (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting huggingface_hub>=0.21.0 (from accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers<=4.56.2,>=4.53.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers<=4.56.2,>=4.53.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch<=2.8.0,>=2.7.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets<=4.1.1,>=4.0.0->llmcompressor[transformers]->-r requirements-awq.txt (line 3))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting click>=8.0.0 (from typer-slim->huggingface_hub>=0.21.0->accelerate->-r requirements-awq.txt (line 4))\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Using cached compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_ml_py-13.580.82-py3-none-any.whl (49 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m822.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m146.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached llmcompressor-0.8.1-py3-none-any.whl (273 kB)\n",
            "Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-ml-py, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, tqdm, sympy, six, setuptools, safetensors, regex, pyyaml, pyarrow, psutil, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, MarkupSafe, loguru, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, triton, requests, python-dateutil, pydantic-core, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, aiosignal, pydantic, pandas, nvidia-cusolver-cu12, huggingface_hub, aiohttp, torch, tokenizers, transformers, datasets, accelerate, compressed-tensors, llmcompressor\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 13.580.82\n",
            "    Uninstalling nvidia-ml-py-13.580.82:\n",
            "      Successfully uninstalled nvidia-ml-py-13.580.82\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.6.0\n",
            "    Uninstalling xxhash-3.6.0:\n",
            "      Successfully uninstalled xxhash-3.6.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.4.1\n",
            "    Uninstalling propcache-0.4.1:\n",
            "      Successfully uninstalled propcache-0.4.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.13.1.3\n",
            "    Uninstalling nvidia-cufile-cu12-1.13.1.3:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: loguru\n",
            "    Found existing installation: loguru 0.7.3\n",
            "    Uninstalling loguru-0.7.3:\n",
            "      Successfully uninstalled loguru-0.7.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.2\n",
            "    Uninstalling aiohttp-3.13.2:\n",
            "      Successfully uninstalled aiohttp-3.13.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "  Attempting uninstall: compressed-tensors\n",
            "    Found existing installation: compressed-tensors 0.12.2\n",
            "    Uninstalling compressed-tensors-0.12.2:\n",
            "      Successfully uninstalled compressed-tensors-0.12.2\n",
            "  Attempting uninstall: llmcompressor\n",
            "    Found existing installation: llmcompressor 0.8.1\n",
            "    Uninstalling llmcompressor-0.8.1:\n",
            "      Successfully uninstalled llmcompressor-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 compressed-tensors-0.12.2 datasets-4.1.1 dill-0.4.0 filelock-3.20.1 frozenlist-1.8.0 fsspec-2025.9.0 hf-xet-1.2.0 huggingface_hub-0.36.0 idna-3.11 jinja2-3.1.6 llmcompressor-0.8.1 loguru-0.7.3 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.16 networkx-3.6.1 numpy-2.3.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-ml-py-13.580.82 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pandas-2.3.3 pillow-11.3.0 propcache-0.4.1 psutil-7.1.3 pyarrow-22.0.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 setuptools-80.9.0 six-1.17.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.56.2 triton-3.4.0 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 xxhash-3.6.0 yarl-1.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "aiohappyeyeballs",
                  "aiohttp",
                  "aiosignal",
                  "attr",
                  "certifi",
                  "dateutil",
                  "frozenlist",
                  "idna",
                  "multidict",
                  "numpy",
                  "packaging",
                  "pandas",
                  "propcache",
                  "psutil",
                  "pyarrow",
                  "pytz",
                  "requests",
                  "six",
                  "tqdm",
                  "urllib3",
                  "yarl"
                ]
              },
              "id": "20da2581edfc465ca610390c0bbb2b65"
            }
          },
          "metadata": {}
        }
      ],
      "id": "xkGgEoRfLFN_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now install llmcompressor hoping it adapts to the existing torch==2.9.1, or gives a clear conflict\n",
        "!pip install llmcompressor[transformers]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxb-8z2rNXPm",
        "outputId": "277818cc-5252-4f86-de56-315723a4b75b"
      },
      "id": "Nxb-8z2rNXPm",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llmcompressor in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: loguru<=0.7.3,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (0.7.3)\n",
            "Requirement already satisfied: pyyaml<=6.0.3,>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (6.0.3)\n",
            "Requirement already satisfied: numpy<=2.3.3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.3.3)\n",
            "Requirement already satisfied: requests<=2.32.5,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.32.5)\n",
            "Requirement already satisfied: tqdm<=4.67.1,>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.67.1)\n",
            "Requirement already satisfied: torch<=2.8.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.8.0)\n",
            "Requirement already satisfied: transformers<=4.56.2,>=4.53.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.56.2)\n",
            "Requirement already satisfied: datasets<=4.1.1,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.1.1)\n",
            "Requirement already satisfied: accelerate<=1.10.1,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (1.10.1)\n",
            "Requirement already satisfied: nvidia-ml-py<=13.580.82,>=12.560.30 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (13.580.82)\n",
            "Requirement already satisfied: pillow<=11.3.0,>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (11.3.0)\n",
            "Requirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (0.12.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->llmcompressor) (2.12.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (7.1.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.20.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (2.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate<=1.10.1,>=1.6.0->llmcompressor) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<=2.8.0,>=2.7.0->llmcompressor) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.8.0,>=2.7.0->llmcompressor) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llmcompressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJT-r5tkOcF2",
        "outputId": "5a4788d3-2d76-485f-d207-40b7ad29f5e0"
      },
      "id": "WJT-r5tkOcF2",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llmcompressor\n",
            "  Using cached llmcompressor-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: loguru<=0.7.3,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (0.7.3)\n",
            "Requirement already satisfied: pyyaml<=6.0.3,>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (6.0.3)\n",
            "Requirement already satisfied: numpy<=2.3.3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.3.3)\n",
            "Requirement already satisfied: requests<=2.32.5,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.32.5)\n",
            "Requirement already satisfied: tqdm<=4.67.1,>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.67.1)\n",
            "Requirement already satisfied: torch<=2.8.0,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (2.8.0)\n",
            "Requirement already satisfied: transformers<=4.56.2,>=4.53.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.56.2)\n",
            "Requirement already satisfied: datasets<=4.1.1,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (4.1.1)\n",
            "Requirement already satisfied: accelerate<=1.10.1,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (1.10.1)\n",
            "Requirement already satisfied: nvidia-ml-py<=13.580.82,>=12.560.30 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (13.580.82)\n",
            "Requirement already satisfied: pillow<=11.3.0,>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (11.3.0)\n",
            "Requirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from llmcompressor) (0.12.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->llmcompressor) (2.12.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (7.1.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.6.0->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.20.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (2.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.1.1,>=4.0.0->llmcompressor) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=2.7.0->llmcompressor) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.56.2,>=4.53.0->llmcompressor) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate<=1.10.1,>=1.6.0->llmcompressor) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->compressed-tensors==0.12.2->llmcompressor) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<=2.8.0,>=2.7.0->llmcompressor) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.8.0,>=2.7.0->llmcompressor) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<=4.1.1,>=4.0.0->llmcompressor) (1.17.0)\n",
            "Using cached llmcompressor-0.8.1-py3-none-any.whl (273 kB)\n",
            "Installing collected packages: llmcompressor\n",
            "Successfully installed llmcompressor-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4ee9677f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ee9677f",
        "outputId": "91c85b79-bb98-4916-c156-c377b72619b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWQ dependencies not available. Install requirements-awq.txt\n",
            "pip install 'llm-compressor[transformers]'\n"
          ]
        }
      ],
      "source": [
        "# Export AWQ (requires requirements-awq.txt)\n",
        "!python scripts/export_awq.py --model microsoft/phi-2 --adapter checkpoints/automotive-adapter --output exports/automotive-awq-4bit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llmcompressor.transformers import oneshot\n",
        "from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "XXlcH7tINwKc",
        "outputId": "74a17c79-d635-4046-dba9-92bf095cdfc6"
      },
      "id": "XXlcH7tINwKc",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2302\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2303\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2331\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOSS_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_flash_attention_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_import_flash_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/loss/loss_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_d_fine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDFineForObjectDetectionLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_deformable_detr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeformableDetrForObjectDetectionLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeformableDetrForSegmentationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/loss/loss_d_fine.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from .loss_for_object_detection import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbox_iou\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/loss/loss_for_object_detection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_to_corners_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from .image_utils import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchvision::nms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeta_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0muse_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         use_lib._register_fake(\n\u001b[0m\u001b[1;32m   1070\u001b[0m             \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_override\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_override\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m_register_fake\u001b[0;34m(self, op_name, fn, _stacklevel, allow_override)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         handle = entry.fake_impl.register(\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mfunc_to_register\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_override\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_override\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/fake_impl.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, func, source, lib, allow_override)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 )\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_has_kernel_for_dispatch_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Meta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1829645538.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moneshot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTQModifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from llmcompressor.core.session_functions import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mactive_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEventType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifecycle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompressionLifecycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelParameterizedLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompressionSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/core/lifecycle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEventType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecipeArgsInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecipeInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecipeStageInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/core/state.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloguru\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoggerManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"State\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hardware\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ModifiedState\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/metrics/logger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mLogStepType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllmcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_package_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ruff: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llmcompressor/utils/dev.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTORCH_INIT_FUNCTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAFE_WEIGHTS_INDEX_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_INDEX_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2303\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m                 raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m   2306\u001b[0m                     \u001b[0;34mf\"Could not import module '{name}'. Are this object's requirements defined correctly?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m                 ) from e\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96c30ee153054165806354bcc75b12f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f79e566210a843bcbd53b65e8a4e5333",
              "IPY_MODEL_7ddadcb88fb942a186e9002974c79116",
              "IPY_MODEL_d30d7bc908b449a4a85370d7cdfcbde7"
            ],
            "layout": "IPY_MODEL_eeb3c2cfdcee44a8a0c55cafdcef5b11"
          }
        },
        "f79e566210a843bcbd53b65e8a4e5333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4361ed9d6446f4a47def769dad9dc4",
            "placeholder": "​",
            "style": "IPY_MODEL_7aff40313a38417197f556fb01f3fcfd",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "7ddadcb88fb942a186e9002974c79116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a2be8d764be478fa70a9679118dbedd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050b77c6ee8d4539a0e1ac82ce3d9a0a",
            "value": 0
          }
        },
        "d30d7bc908b449a4a85370d7cdfcbde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bedb6e3102c4e93a5ac2ae88d89d893",
            "placeholder": "​",
            "style": "IPY_MODEL_b503a1e6e0ff4db296243dfec48e93be",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "eeb3c2cfdcee44a8a0c55cafdcef5b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4361ed9d6446f4a47def769dad9dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aff40313a38417197f556fb01f3fcfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a2be8d764be478fa70a9679118dbedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050b77c6ee8d4539a0e1ac82ce3d9a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bedb6e3102c4e93a5ac2ae88d89d893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b503a1e6e0ff4db296243dfec48e93be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}